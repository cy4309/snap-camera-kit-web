import { useCallback, useEffect, useRef, useState } from "react";
import { useCameraKit } from "./hooks/useCameraKit";
import { createMediaStreamSource, Transform2D } from "@snap/camera-kit";
import BaseButton from "./components/BaseButton";

function App() {
  const { session, lenses } = useCameraKit();
  const canvasContainerRef = useRef<HTMLDivElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [photo, setPhoto] = useState<string | null>(null);
  const [recording, setRecording] = useState(false);
  const [videoUrl, setVideoUrl] = useState<string | null>(null);
  const [facingMode, setFacingMode] = useState<"user" | "environment">(
    "environment"
  );
  const [currentLensIndex, setCurrentLensIndex] = useState(0);
  const [recordingTime, setRecordingTime] = useState(0);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  // const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  // const [videoDataUrl, setVideoDataUrl] = useState<string | null>(null);

  const startCameraKit = useCallback(async () => {
    const mediaStream = await navigator.mediaDevices.getUserMedia({
      // video: true,
      // video: { width: { ideal: 1280 } },
      // video: { width: { ideal: 3840 }, height: { ideal: 2160 } },
      video: {
        // width: { ideal: 720 }, // mobile
        width: { ideal: 1920 },
        height: { ideal: 1080 },
        facingMode: facingMode,
      },
    });

    const source = createMediaStreamSource(mediaStream, {
      transform: facingMode === "user" ? Transform2D.MirrorX : undefined,
    });

    session.setSource(source);
    // session.applyLens(lenses[0]);
    session.play("live");
  }, [session, lenses, facingMode]);

  useEffect(() => {
    startCameraKit();
  }, [startCameraKit]);

  useEffect(() => {
    canvasContainerRef?.current?.replaceWith(session.output.live);
  }, [session]);

  useEffect(() => {
    if (session && lenses.length > 0) {
      // console.log(lenses);
      session.applyLens(lenses[currentLensIndex]);
    }
  }, [session, lenses, currentLensIndex]);

  // éŒ„å½±çµæŸæ™‚è‡ªå‹•æ¸…é™¤è¨ˆæ™‚å™¨
  useEffect(() => {
    if (!recording && recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }
  }, [recording]);

  // æ™‚é–“æ ¼å¼åŒ–
  const formatTime = (sec: number) => {
    const m = Math.floor(sec / 60)
      .toString()
      .padStart(2, "0");
    const s = (sec % 60).toString().padStart(2, "0");
    return `${m}:${s}`;
  };

  const isLineWebView = () => {
    return /Line/i.test(navigator.userAgent);
  };

  const toggleFacingMode = () => {
    setFacingMode((prev) => (prev === "user" ? "environment" : "user"));
  };

  // const toggleAudio = () => {
  //   setIsAudioEnabled((prev) => !prev);
  // };

  const takePhoto = () => {
    if (!canvasRef.current || !session.output.live) return;

    // å–å¾— live DOM çš„å¯¬é«˜
    const live = session.output.live as HTMLVideoElement | HTMLCanvasElement;
    const width =
      live instanceof HTMLVideoElement ? live.videoWidth : live.width;
    const height =
      live instanceof HTMLVideoElement ? live.videoHeight : live.height;

    // è¨­å®š canvas å°ºå¯¸
    canvasRef.current.width = width;
    canvasRef.current.height = height;

    const ctx = canvasRef.current.getContext("2d");
    if (!ctx) return;

    ctx.drawImage(live, 0, 0, width, height);

    const imageData = canvasRef.current.toDataURL("image/png");
    setPhoto(imageData);

    // ä¸‹è¼‰åœ–ç‰‡
    const link = document.createElement("a");
    link.href = imageData;
    link.download = "snap-photo.png";
    link.click();
  };

  // éŒ„å½±åŠŸèƒ½
  const startRecording = () => {
    if (!session.output.live) return;
    // å–å¾— live video stream
    let stream: MediaStream | null = null;
    if (session.output.live instanceof HTMLVideoElement) {
      stream = session.output.live.srcObject as MediaStream;
    } else if (session.output.live.captureStream) {
      stream = session.output.live.captureStream();
    }
    if (!stream) return;

    recordedChunksRef.current = [];
    const mediaRecorder = new MediaRecorder(stream, { mimeType: "video/mp4" });
    mediaRecorderRef.current = mediaRecorder;

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        recordedChunksRef.current.push(event.data);
      }
    };

    mediaRecorder.onstop = () => {
      const blob = new Blob(recordedChunksRef.current, { type: "video/mp4" });
      setVideoUrl(URL.createObjectURL(blob));

      // æ–°å¢ï¼šç”¢ç”Ÿ DataURL çµ¦ iOS ç”¨
      // const reader = new FileReader();
      // reader.onloadend = () => {
      //   setVideoDataUrl(reader.result as string); // æ–°å¢ä¸€å€‹ state
      // };
      // reader.readAsDataURL(blob);
    };

    mediaRecorder.start();
    setRecording(true);
    setVideoUrl(null);
    setRecordingTime(0);
    // é–‹å§‹è¨ˆæ™‚
    recordingIntervalRef.current = setInterval(() => {
      setRecordingTime((prev) => prev + 1);
    }, 1000);
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setRecording(false);
    // åœæ­¢è¨ˆæ™‚
    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }
  };

  return (
    <div className="relative w-full h-[100dvh] min-w-[320px] min-h-screen flex flex-col justify-center items-center">
      <div ref={canvasContainerRef} />

      {!photo && !videoUrl && (
        <div className="w-1/2 absolute bottom-30 flex flex-col justify-center items-center">
          {/* <BaseButton onClick={toggleAudio} className="px-4 py-2 opacity-80 font-bold rounded-xl shadow-md">
            {isAudioEnabled ? "ğŸ”Š" : "ğŸ”‡"}
          </BaseButton> */}
          <canvas ref={canvasRef} className="hidden" />

          <div className="w-full gap-2 flex overflow-x-auto custom-scrollbar">
            {lenses.map((lens, i) => (
              <img
                key={lens.id}
                onClick={() => setCurrentLensIndex(i)}
                src={lens.iconUrl}
                alt={`æ¿¾é¡${i + 1}`}
                // className="w-12 cursor-pointer"
                className={`w-12 cursor-pointer rounded-xl ${
                  currentLensIndex === i
                    ? "bg-blue-500 text-white"
                    : "bg-gray-200"
                }`}
              />
            ))}
          </div>

          <div className="flex gap-2 mt-4">
            <BaseButton
              onClick={takePhoto}
              className="px-4 py-2 opacity-80 font-bold rounded-xl shadow-md"
            >
              ğŸ“¸
            </BaseButton>
            {!recording ? (
              <BaseButton
                onClick={startRecording}
                className="px-4 py-2 opacity-80 font-bold rounded-xl shadow-md"
              >
                âºï¸
              </BaseButton>
            ) : (
              <div className="flex items-center gap-2">
                <BaseButton
                  onClick={stopRecording}
                  className="px-4 py-2 opacity-80 font-bold rounded-xl shadow-md"
                >
                  â¹ï¸
                </BaseButton>
                <span className="text-red-500 font-mono font-bold min-w-[48px] text-lg">
                  {formatTime(recordingTime)}
                </span>
              </div>
            )}
            <BaseButton
              onClick={toggleFacingMode}
              className="px-4 py-2 font-bold rounded-xl shadow-md"
            >
              ğŸ”„
            </BaseButton>
          </div>
        </div>
      )}

      {/* é è¦½ç…§ç‰‡ */}
      {photo && (
        <div className="fixed inset-0 z-20 bg-black/80 flex flex-col justify-center items-center">
          <img
            src={photo}
            alt="Snapshot"
            className="rounded-xl shadow-md max-w-md"
          />
          <BaseButton
            onClick={() => setPhoto(null)}
            className="w-1/4 absolute bottom-30"
          >
            è¿”å›
          </BaseButton>
        </div>
      )}

      {/* é è¦½å½±ç‰‡ */}
      {videoUrl && (
        <div className="fixed inset-0 z-20 bg-black/80 flex flex-col justify-center items-center">
          <video
            src={videoUrl}
            controls
            className="rounded-xl shadow-md max-w-md"
          />

          <div className="absolute bottom-50 my-4 gap-4 w-1/2 flex justify-center items-center">
            {/* é›»è…¦/Android ä¸‹è¼‰ */}
            {isLineWebView() ? (
              <div className="text-red-500 font-bold text-center">
                LINEå…§å»ºç€è¦½å™¨ä¸æ”¯æ´ä¸‹è¼‰ï¼Œè«‹é»ã€Œåœ¨ç€è¦½å™¨é–‹å•Ÿã€å†ä¸‹è¼‰å½±ç‰‡ã€‚
              </div>
            ) : (
              <BaseButton className="w-full !bg-blue-500 text-white">
                <a href={videoUrl} download="snap-video.mp4">
                  å½±ç‰‡ä¸‹è¼‰
                </a>
              </BaseButton>
            )}
            {/* iOS ä¸‹è¼‰ï¼ˆDataURLï¼‰ */}
            {/* {videoDataUrl && (
              <BaseButton className="w-full !bg-blue-500 text-white">
                <a href={videoDataUrl} download="snap-video.mp4">
                  iOS ä¸‹è¼‰
                </a>
              </BaseButton>
            )} */}
          </div>

          <BaseButton
            onClick={() => {
              setVideoUrl(null);
              // setVideoDataUrl(null);
            }}
            className="w-1/4 absolute bottom-30"
          >
            è¿”å›
          </BaseButton>
        </div>
      )}
    </div>
  );
}

export default App;
